<!-- HTML header for doxygen 1.8.6-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.6"/>
<title>Open Detection: Detection 2D</title>
    <link rel="stylesheet" href="http://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="http://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <style>
        .carousel-inner > .item > img,
        .carousel-inner > .item > a > img {
            width: 70%;
            margin: auto;
        }
    </style>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
  $(window).load(resizeHeight);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() {
    if ($('.searchresults').length > 0) { searchBox.DOMSearchField().focus(); }
  });
</script>
<link rel="search" href="search-opensearch.php?v=opensearch.xml" type="application/opensearchdescription+xml" title="Open Detection"/>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="customdoxygen.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">Open Detection
   &#160;<span id="projectnumber">1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.6 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>OD</span></a></li>
      <li class="current"><a href="pages.html"><span>User&#160;Guide</span></a></li>
      <li><a href="usergroup0.html"><span>API&#160;Documentation</span></a></li>
      <li><a href="installation_instruction.html"><span>Downloads</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
          <div class="left">
            <form id="FSearchBox" action="search.php" method="get">
              <img id="MSearchSelect" src="search/mag.png" alt=""/>
              <input type="text" id="MSearchField" name="query" value="Search" size="20" accesskey="S" 
                     onfocus="searchBox.OnSearchFieldFocus(true)" 
                     onblur="searchBox.OnSearchFieldFocus(false)"/>
            </form>
          </div><div class="right"></div>
        </div>
      </li>
    </ul>
  </div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('detection_2d.html','');});
</script>
<div id="doc-content">
<div class="header">
  <div class="headertitle">
<div class="title">Detection 2D </div>  </div>
</div><!--header-->
<div class="contents">
<div class="toc"><h3>Table of Contents</h3>
<ul><li class="level1"><a href="#detection_2d1">Detection 2D </a><ul><li class="level2"><a href="#detection_2d2">HOG feature based detection</a><ul><li class="level3"><a href="#detection_2d3">Data</a></li>
<li class="level3"><a href="#detection_2d4">Code explanation</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="textblock"><h1><a class="anchor" id="detection_2d1"></a>
Detection 2D </h1>
<p>This article goes through the 2D detection methods covered in OD. Specifically, it covers the classes - <a class="el" href="classod_1_1g2d_1_1_o_d_h_o_g_detector.html" title="A linear classifier for HOG features. ">od::g2d::ODHOGDetector</a> through a tutorial.</p>
<p>2D detection methods are performed by the classes Detector2D. They accept a <code>SceneImage</code> and performs detection/recognition on them. Currently Detector2Ds are classified into g2d and l2d namespaces. g2d covers detection methods which uses global 2D features (like HOG/Cascade) while l2d covers detection methods which uses local 2D features (like SIFT/SURF/ORB) for detection/recognition. Different 2D detectors that are available currently: <a class="el" href="classod_1_1g2d_1_1_o_d_h_o_g_detector.html" title="A linear classifier for HOG features. ">od::g2d::ODHOGDetector</a>, <a class="el" href="classod_1_1g2d_1_1_o_d_cascade_detector.html" title="A class for detection using Cascade classifiers. ">od::g2d::ODCascadeDetector</a>, <a class="el" href="classod_1_1g2d_1_1_o_d_face_recognizer.html" title="A facerecognizer based on EigenFace and FischerFace algorithms. ">od::g2d::ODFaceRecognizer</a>, <a class="el" href="classod_1_1l2d_1_1_o_d_c_a_d_recognizer2_d_local.html" title="Simple RANSAC based 3D object recognizer. ">od::l2d::ODCADRecognizer2DLocal</a></p>
<h2><a class="anchor" id="detection_2d2"></a>
HOG feature based detection</h2>
<p>HOGDetector is a HOG feature based linear classifier. It accepts an image (<a class="el" href="classod_1_1_o_d_scene_image.html" title="Class for Image Scene. ">od::ODSceneImage</a>), computes its HOG feature (in a multiscale mannar for detectOmni() and a single descriptor from the resized image for detect()), runs a linear SVM obtained either by HOGTrainer through training or some default ones (from OpenCV), and informs if the classifier is true thereby providing detection.</p>
<p>A complete example including training is provided in <code>examples/objectdetector/od_hog_train.cpp</code>. For positive and negetive example get the data from the INRIA human dataset: <a href="http://pascal.inrialpes.fr/data/human/">http://pascal.inrialpes.fr/data/human/</a>.</p>
<p>In this tutorial we will go through a more complete application in present in <code>examples/apps/global2D/od_multihog_app.cpp</code>. The code is provided here verbatime:</p>
<div class="fragment"><div class="line"><span class="comment">/** \brief Example of the usage of HOG detector</span></div>
<div class="line"><span class="comment">   *</span></div>
<div class="line"><span class="comment">   * \author Kripasindhu Sarkar</span></div>
<div class="line"><span class="comment">   *</span></div>
<div class="line"><span class="comment">   */</span></div>
<div class="line"></div>
<div class="line"><span class="preprocessor">#include &quot;detectors/global2D/detection/ODHOGDetector.h&quot;</span></div>
<div class="line"><span class="preprocessor">#include &quot;common/utils/ODFrameGenerator.h&quot;</span></div>
<div class="line"></div>
<div class="line"><span class="preprocessor">#include &quot;common/pipeline/ObjectDetector.h&quot;</span></div>
<div class="line"><span class="preprocessor">#include &quot;common/pipeline/ODDetection.h&quot;</span></div>
<div class="line"></div>
<div class="line"></div>
<div class="line"><span class="keyword">using namespace </span>od;</div>
<div class="line"><span class="keyword">using namespace </span>std;</div>
<div class="line"></div>
<div class="line">cv::Size sizesingle(640, 480);</div>
<div class="line"></div>
<div class="line"><span class="keywordtype">int</span> main(<span class="keywordtype">int</span> argc, <span class="keywordtype">char</span> *argv[])</div>
<div class="line">{</div>
<div class="line">  std::string trained_data_dir(argv[1]), input_video(argv[2]), output_video = <span class="stringliteral">&quot;output.avi&quot;</span>;</div>
<div class="line">  <span class="keywordflow">if</span> (argc &gt; 3) output_video = argv[3];</div>
<div class="line"></div>
<div class="line"></div>
<div class="line">  <span class="comment">//get 3 detectors of different types</span></div>
<div class="line">  vector&lt;string&gt; messages; messages.push_back(<span class="stringliteral">&quot;Original&quot;</span>);</div>
<div class="line">  vector&lt;g2d::ODHOGDetector*&gt; detectors;</div>
<div class="line">  <a class="code" href="classod_1_1g2d_1_1_o_d_h_o_g_detector.html">g2d::ODHOGDetector</a> *detector1 = <span class="keyword">new</span> <a class="code" href="classod_1_1g2d_1_1_o_d_h_o_g_detector.html">g2d::ODHOGDetector</a>; <span class="comment">//</span></div>
<div class="line">  messages.push_back(<span class="stringliteral">&quot;OpenCV Default People&quot;</span>); detectors.push_back(detector1);</div>
<div class="line"></div>
<div class="line">  <a class="code" href="classod_1_1g2d_1_1_o_d_h_o_g_detector.html">g2d::ODHOGDetector</a> *detector2 = <span class="keyword">new</span> <a class="code" href="classod_1_1g2d_1_1_o_d_h_o_g_detector.html">g2d::ODHOGDetector</a>; detector2-&gt;<a class="code" href="classod_1_1g2d_1_1_o_d_h_o_g_detector.html#a47c57b507c965c09dfd8371121239979">setSvmtype</a>(g2d::ODHOGDetector::OD_DAIMLER_PEOPLE);</div>
<div class="line">  messages.push_back(<span class="stringliteral">&quot;OpenCV Daimler People&quot;</span>); detectors.push_back(detector2);</div>
<div class="line"></div>
<div class="line">  <a class="code" href="classod_1_1g2d_1_1_o_d_h_o_g_detector.html">g2d::ODHOGDetector</a> *detector3 = <span class="keyword">new</span> <a class="code" href="classod_1_1g2d_1_1_o_d_h_o_g_detector.html">g2d::ODHOGDetector</a>(trained_data_dir);</div>
<div class="line">  messages.push_back(<span class="stringliteral">&quot;Custom HOG from trained data&quot;</span>); detectors.push_back(detector3);</div>
<div class="line"></div>
<div class="line">  <span class="comment">//init all detectors</span></div>
<div class="line">  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; detectors.size(); i++) detectors[i]-&gt;init();</div>
<div class="line"></div>
<div class="line">  <span class="comment">//get scenes</span></div>
<div class="line">  od::ODFrameGenerator&lt;od::ODSceneImage, od::GENERATOR_TYPE_DEVICE&gt; frameGenerator(input_video); </div>
<div class="line">  cv::VideoWriter videoWriter(output_video, CV_FOURCC(<span class="charliteral">&#39;M&#39;</span>,<span class="charliteral">&#39;J&#39;</span>,<span class="charliteral">&#39;P&#39;</span>,<span class="charliteral">&#39;G&#39;</span>), 25, sizesingle * 2, <span class="keyword">true</span>);</div>
<div class="line"></div>
<div class="line"></div>
<div class="line">  <span class="comment">//GUI</span></div>
<div class="line">  cv::namedWindow(<span class="stringliteral">&quot;Overlay&quot;</span>, cv::WINDOW_NORMAL);</div>
<div class="line">  <span class="keywordflow">while</span>(frameGenerator.isValid() &amp;&amp; cv::waitKey(33) != 27)</div>
<div class="line">  {</div>
<div class="line">    <a class="code" href="classod_1_1_o_d_scene_image.html">od::ODSceneImage</a> * scene = frameGenerator.getNextFrame();</div>
<div class="line"></div>
<div class="line">    vector&lt;cv::Mat&gt; images_to_show;</div>
<div class="line">    images_to_show.push_back(scene-&gt;<a class="code" href="classod_1_1_o_d_scene_image.html#aa612c7d253de19c5e168b5f4c64e71b8">getCVImage</a>()); <span class="comment">//push the first image</span></div>
<div class="line"></div>
<div class="line">    <span class="comment">//detect 3 times</span></div>
<div class="line">    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; detectors.size(); i++)</div>
<div class="line">    {</div>
<div class="line">      <a class="code" href="classod_1_1_o_d_detections2_d.html">ODDetections2D</a> *detections =  detectors[i]-&gt;detectOmni(scene);</div>
<div class="line">      <span class="keywordflow">if</span>(detections-&gt;<a class="code" href="classod_1_1_o_d_detections.html#acecd430dee656213a2a19832dd7a47d6">size</a>() &gt; 0)</div>
<div class="line">        images_to_show.<a class="code" href="classod_1_1_o_d_detections.html#a076cbfeb953d1e8c0fef206b076e9a41">push_back</a>(detections-&gt;<a class="code" href="classod_1_1_o_d_detections2_d.html#a3297fb185a951414197e1db893a4cdaf">renderMetainfo</a>(*scene).<a class="code" href="classod_1_1_o_d_scene_image.html#aa612c7d253de19c5e168b5f4c64e71b8">getCVImage</a>());</div>
<div class="line">      <span class="keywordflow">else</span> images_to_show.push_back(scene-&gt;<a class="code" href="classod_1_1_o_d_scene_image.html#aa612c7d253de19c5e168b5f4c64e71b8">getCVImage</a>());</div>
<div class="line">    }</div>
<div class="line"></div>
<div class="line">    cv::Mat multiimage = <a class="code" href="namespaceod.html#a055d1749c9212f40b840643989d3e3ab">makeCanvasMultiImages</a>(images_to_show, sizesingle, messages);</div>
<div class="line">    cv::imshow(<span class="stringliteral">&quot;Overlay&quot;</span>, multiimage);</div>
<div class="line">    videoWriter &lt;&lt; multiimage;</div>
<div class="line"></div>
<div class="line">    <span class="keyword">delete</span> scene;</div>
<div class="line">  }</div>
<div class="line"></div>
<div class="line">  <span class="keywordflow">return</span> 0;</div>
<div class="line">}</div>
</div><!-- fragment --><h3><a class="anchor" id="detection_2d3"></a>
Data</h3>
<p>This app compares the results of HOG based detection with three different trained classifiers. For this app you need a pre-trained hog descriptor in your <code>trained_data</code> directory. You can either train as in <code>examples/objectdetector/od_hog_train.cpp</code>, or get the OD pre-trained data from the <a class="el" href="getting_started.html#getting_started2">Data Repository</a>.</p>
<p>For the query video, get a clip containing many pedestrians. For example you can get one from <a href="http://www.robots.ox.ac.uk/ActiveVision/Research/Projects/2009bbenfold_headpose/project.html#datasets">http://www.robots.ox.ac.uk/ActiveVision/Research/Projects/2009bbenfold_headpose/project.html#datasets</a></p>
<p>Run the app from the build directory as: </p>
<pre class="fragment">examples/apps/od_multihog_app &lt;path_to_data&gt;/trained_data/ &lt;input_pedestrian_video&gt; &lt;output_comparison_video_with_detection&gt;
</pre><p>Depending on the input video, you will see something like the following:</p>
 
<div align="center">
<iframe width="800" height="600" src="https://www.youtube.com/embed/NaED6B-S4ks" frameborder="0" allowfullscreen></iframe>
</div>
<h3><a class="anchor" id="detection_2d4"></a>
Code explanation</h3>
<p>We first init 3 different instances of HOGDetector of different settings. </p>
<pre class="fragment">  vector&lt;g2d::ODHOGDetector*&gt; detectors;
  g2d::ODHOGDetector *detector1 = new g2d::ODHOGDetector; //
  messages.push_back("OpenCV Default People"); detectors.push_back(detector1);

  g2d::ODHOGDetector *detector2 = new g2d::ODHOGDetector; detector2-&gt;setSvmtype(g2d::ODHOGDetector::OD_DAIMLER_PEOPLE);
  messages.push_back("OpenCV Daimler People"); detectors.push_back(detector2);

  g2d::ODHOGDetector *detector3 = new g2d::ODHOGDetector(trained_data_dir);
  messages.push_back("Custom HOG from trained data"); detectors.push_back(detector3);      
</pre><p>You can set different types of linear SVMs for HOG detector using <code>setSvmtype</code> function. For adding a custom SVM use the type OD_CUSTOM and set the linear SVM weight vector using <code>setSVMDetector()</code>. You have to then update the other HOG detector parameters accordingly (like winSize etc) with which the your SVM was trained. If you give a trained data directory, it will use the xml file from the directory. Here, we set three different available HOG detectors.</p>
<p>After setting all the parameters you need to call <code>init()</code> which is done in the following line. </p>
<pre class="fragment"> //init all detectors
 for (int i = 0; i &lt; detectors.size(); i++) detectors[i]-&gt;init();
</pre><p>Then we create a FrameGenerator object, which is a templated class for grabbing both Images and Point Clouds (from kinect). Use od::GENERATOR_TYPE_DEVICE for grabbing frames from camera (kinekt for Point Cloud) or video which is done in the following line. </p>
<pre class="fragment">  //get scenes
  od::ODFrameGenerator&lt;od::ODSceneImage, od::GENERATOR_TYPE_DEVICE&gt; frameGenerator(input_video); 
</pre><p>The next valid frame can be accessed now by <code>frameGenerator.getNextFrame();</code> which is being done in loop until exhaustion.</p>
<p>Each ImageScene is then checked by the detector using the detectOmni() function which searches the whole image for detections. The resultant Detections2D contains information about the detections made (like Type/Bounding box etc). We use an function <code>renderMetainfo</code> to draw the bounding box of all the detections made. </p>
<pre class="fragment">//detect 3 times
for (int i = 0; i &lt; detectors.size(); i++)
{
  ODDetections2D *detections =  detectors[i]-&gt;detectOmni(scene);
  if(detections-&gt;size() &gt; 0)
    images_to_show.push_back(detections-&gt;renderMetainfo(*scene).getCVImage());
  else images_to_show.push_back(scene-&gt;getCVImage());
}
</pre><p>The function <code><a class="el" href="namespaceod.html#a055d1749c9212f40b840643989d3e3ab" title="Makes composite image from the given images. ">od::makeCanvasMultiImages</a></code> take N images and concatenate them in order forming a big image with messages. That concatenated image with having information from all the detectors are then being shown. </p>
<pre class="fragment">cv::Mat multiimage = makeCanvasMultiImages(images_to_show, sizesingle, messages);
cv::imshow("Overlay", multiimage);</pre> </div></div><!-- contents -->
</div><!-- doc-content -->
<!-- HTML footer for doxygen 1.8.6-->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="tutorial_root.html">User Guide</a></li>
    <li class="footer">Send your queries <a href="mailto:kripasindhu.sarkar@dfki.de?Subject=OpenDetection" target="_top">here</a>.</li>
  </ul>
</div>
</body>
</html>
